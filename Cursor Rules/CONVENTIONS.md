# Implementation Conventions - INS-001

**READ THIS FIRST BEFORE WRITING ANY CODE**

This document defines the rules for implementing INS-001. Following these conventions prevents bugs, security vulnerabilities, and construct validity issues.

---

## üö® CRITICAL RULES (Never Violate)

### 1. NEVER Use Service Key in Route Handlers

```python
# ‚ùå WRONG - Bypasses all RLS, anyone can read any data
supabase = create_client(URL, SERVICE_KEY)

# ‚úÖ CORRECT - Uses user JWT, RLS enforced
supabase, user = await get_authenticated_client(credentials)
```

The service key is ONLY for background jobs (profile computation, cleanup).

### 2. Word Validation Rules (IMPORTANT)

#### ALL Words Are OPEN (no vocabulary restrictions)

Seeds, clues, and guesses all follow the same rule: **accept any word**.

```python
# ‚úÖ CORRECT - No validation needed
seed_word = request.seed_word.lower().strip()
clues_clean = [c.lower().strip() for c in request.clues]
guesses_clean = [g.lower().strip() for g in request.guesses]

# ‚ùå WRONG - Don't validate against vocabulary
if not await validate_word(supabase, word):
    raise HTTPException(400, "Word not in vocabulary")
```

Users can enter ANY word for seeds, clues, or guesses:
- Standard English words
- Domain-specific terms (tachycardia, estoppel)
- Proper nouns (Shakespeare, Obi-Wan)
- Slang and neologisms (rizz, skibidi)
- Foreign words
- Made-up words

#### Why This Is Safe

1. **LLM prompt safety:** XML structure isolates user content, not vocabulary filtering
   ```python
   # XML escaping handles prompt safety
   escaped_clues = [html.escape(c) for c in clues]
   clue_xml = "\n".join(f"  <clue>{c}</clue>" for c in escaped_clues)
   ```

2. **Embeddings:** OpenAI embeds ANY string via subword tokenization

3. **Self-correcting:** Gibberish inputs hurt only that player's score

4. **Consistent UX:** Same rules for all inputs, no confusing "word not found" errors

#### Tracking for Analytics

Track vocabulary membership for research filtering, but don't block:

```python
# Track for research, don't block
seed_in_vocabulary = await check_word_in_vocabulary(supabase, seed_word)
clues_in_vocabulary = [await check_word_in_vocabulary(supabase, c) for c in clues]
```

```sql
-- Filter to vocabulary-only data for strict research validity
SELECT * FROM games WHERE seed_in_vocabulary = TRUE;
```

### 3. Use halfvec for Embeddings if available, or else use vector

Storage uses 16-bit floats to fit in Supabase Free tier:


Index must use `halfvec_cosine_ops` if available:

```sql
-- ‚ùå WRONG
USING ivfflat (embedding vector_cosine_ops)

-- ‚úÖ CORRECT
USING ivfflat (embedding halfvec_cosine_ops)
```

### 4. Lock Rows to Prevent Race Conditions

When updating shared resources, use `FOR UPDATE`:

```sql
-- ‚ùå WRONG - Race condition on concurrent joins
SELECT game_id FROM share_tokens WHERE token = $1

-- ‚úÖ CORRECT - Locks row until transaction completes
SELECT game_id FROM share_tokens WHERE token = $1 FOR UPDATE
```

---

## API Conventions

### Request/Response Shapes

Use ONLY the models defined in `app/models.py`. Do not invent new fields.

### Error Responses

Always return `ErrorResponse`:

```python
raise HTTPException(
    status_code=400,
    detail=ErrorResponse(error="Invalid request", detail="Details here").dict()
)
```

### Status Codes

| Code | Use |
|------|-----|
| 200 | Success |
| 400 | Bad request (validation error) |
| 401 | Not authenticated |
| 403 | Not authorized (RLS blocked) |
| 404 | Resource not found |
| 500 | Server error |

---

## Database Conventions

### Table Names

Lowercase, plural: `games`, `users`, `share_tokens`

### Column Names  

Lowercase, snake_case: `seed_word`, `created_at`, `divergence_score`

### UUIDs

All primary keys are UUIDs, generated by Postgres:

```sql
id UUID PRIMARY KEY DEFAULT gen_random_uuid()
```

### Timestamps

Always use `TIMESTAMPTZ`, never `TIMESTAMP`:

```sql
created_at TIMESTAMPTZ DEFAULT NOW()
```

### Foreign Keys

Always include `ON DELETE CASCADE` for child tables:

```sql
REFERENCES users(id) ON DELETE CASCADE
```

---

## Embedding Conventions

### Model

Always use `text-embedding-3-small`. Do not use other models.

### Contextual Embeddings

For scoring (divergence/convergence), always include context:

```python
# ‚ùå WRONG - No context, polysemy issues
embedding = await get_embedding(word)

# ‚úÖ CORRECT - Context disambiguates meaning
embedding = await get_contextual_embedding(word, context=[seed_word])
```

### On-Demand Embeddings

All words (seeds, clues, guesses) are embedded on-demand via OpenAI:

```python
# Works for any word, not just vocabulary
clue_emb = await get_contextual_embedding(clue, [seed_word])
guess_emb = await get_contextual_embedding(guess, clues)
```

### Noise Floor

Noise floor queries vocabulary embeddings for nearest neighbors:

```python
# Embed seed on-demand, query vocabulary table
floor = await get_noise_floor(supabase, seed_word)
```

---

## Scoring Conventions

### Divergence Formula

```
divergence = 1 - mean(cosine_similarity(clue, floor_centroid))
```

Range: [0, 1]. Higher = more creative.

### Convergence Formula

```
convergence = max(cosine_similarity(guess, seed))
```

With exact match bonus: if guess == seed, return 1.0

Range: [0, 1]. Higher = better communication.

### DO NOT modify these formulas. They define the construct validity.

### Fuzzy Exact Match

For convergence scoring, we treat >99% embedding similarity as exact match.
This handles misspellings and alternate spellings (Ghandi/Gandhi).

```python
FUZZY_EXACT_MATCH_THRESHOLD = 0.99

if max_similarity > FUZZY_EXACT_MATCH_THRESHOLD:
    return 1.0, True  # Treat as exact match
```

---

## LLM Conventions

### Model

Always use `claude-haiku-4-5-20251001`. Do not use other models.

Changing models affects construct validity (LLM Alignment metric).

### Prompt Structure

Always isolate user content in XML tags with escaping:

```python
# ‚úÖ CORRECT - User content isolated and escaped
escaped_clues = [html.escape(c) for c in clues]
prompt = f"""
<clues>
{chr(10).join(f'  <clue>{c}</clue>' for c in escaped_clues)}
</clues>
"""
```

This is the security layer for LLM inputs, not vocabulary validation.

### Temperature

Use 0.3 for guessing (some variety, mostly consistent).

---

## File Organization

```
app/
‚îú‚îÄ‚îÄ main.py              # FastAPI app, routes mounted here
‚îú‚îÄ‚îÄ config.py            # Environment variables
‚îú‚îÄ‚îÄ models.py            # Pydantic models (DO NOT MODIFY SHAPES)
‚îú‚îÄ‚îÄ middleware/
‚îÇ   ‚îî‚îÄ‚îÄ auth.py          # JWT validation (CRITICAL)
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îú‚îÄ‚îÄ games.py         # Game CRUD endpoints
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py    # Noise floor, validation
‚îÇ   ‚îú‚îÄ‚îÄ users.py         # User profile endpoints
‚îÇ   ‚îî‚îÄ‚îÄ share.py         # Share token endpoints
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ embeddings.py    # OpenAI integration
    ‚îú‚îÄ‚îÄ scoring.py       # Divergence/convergence math
    ‚îú‚îÄ‚îÄ llm.py           # Claude guesser
    ‚îî‚îÄ‚îÄ profiles.py      # Profile computation
```

---

## Testing Conventions

### Run scoring tests before any changes:

```bash
python -m pytest app/services/scoring.py -v
```

### Test auth middleware:

```bash
# Should fail with 401
curl -X GET http://localhost:8000/api/v1/users/me

# Should succeed with valid token
curl -X GET http://localhost:8000/api/v1/users/me \
  -H "Authorization: Bearer <token>"
```


---

## Common Mistakes to Avoid

| Mistake | Consequence | Fix |
|---------|-------------|-----|
| Using service key in routes | RLS bypassed, data breach | Use `get_authenticated_client()` |
| Using `vector` instead of `halfvec` | Exceeds 500MB limit | Use `halfvec(1536)` |
| Validating words against vocabulary | Blocks valid use cases, clunky UX | Accept any word |
| Modifying scoring formulas | Breaks construct validity | Use exact formulas |
| Changing LLM model | Breaks LLM Alignment metric | Use Haiku only |
| Missing `FOR UPDATE` | Race conditions | Add to shared resource queries |
| Raw user input in LLM prompts | Prompt injection | XML-escape and isolate |
| Forgetting fuzzy exact match | Misspellings score wrong | Use `FUZZY_EXACT_MATCH_THRESHOLD` |