# INS-001.2: Semantic Bridging

## Overview

INS-001.2 is a variant of the Semantic Associations instrument that measures how individuals construct conceptual bridges between two semantic domains. Unlike INS-001 (single seed word), this task presents participants with an anchor-target pair and asks them to provide clues that connect the two concepts.

**Instrument family:** [INS-001 Semantic Associations](https://phronos.org/methods/observational-chat-analysis/)

**Key change from INS-001:** Instead of diverging from a single concept, participants bridge between two concepts. This shifts the cognitive demand from "free association with novelty" to "relational mapping with creativity."

---

## Theoretical Rationale

Word embeddings capture relational structure well (cf. "king - man + woman = queen"). The space *between* two concepts is geometrically well-defined: a line in high-dimensional space. This allows us to measure divergence as perpendicular distance from the expected path‚Äîhow far the participant's bridge "arcs" away from the obvious route.

This design also addresses the lexical frequency confound in INS-001: embeddings reflect corpus co-occurrence, not human retrieval probability. By measuring deviation from a *path* rather than from a *neighborhood*, we leverage what embeddings actually encode: relational structure.

---

## User Flow

### Phase 1: Sender (Bridge Construction)

```
Step 1: Choose your anchor and target
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ STEP 1 OF 3                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Build a bridge.                                            ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Choose two words to connect. Your clues will help          ‚îÇ
‚îÇ  someone guess which two concepts you're bridging.          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ANCHOR                          TARGET                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ           ‚îÇ                  ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ  [ Suggest ]                    [ Suggest ]                 ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚Üê BACK                              CONTINUE ‚Üí             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Step 2: Provide clues
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ STEP 2 OF 3                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Provide your clues.                                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Enter single-word clues that connect:                      ‚îÇ
‚îÇ  anchor ‚Üê‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Üí target        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  YOUR CLUES                                1-5 words        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  1  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê             ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ  2  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  (optional) ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ  3  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  (optional) ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ  4  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  (optional) ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ  5  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  (optional) ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò             ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚Üê BACK                           SUBMIT CLUES ‚Üí            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Step 3: Share or play against AI
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ STEP 3 OF 3                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Bridge submitted.                                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Your clues: [clue1] ¬∑ [clue2] ¬∑ [clue3] ¬∑ [clue4] ¬∑ [clue5]‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  WHO SHOULD GUESS?                                          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  üîó  Share with someone                              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ      Send a link to a friend or colleague           ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  ü§ñ  Let Haiku guess                                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ      See how Claude Haiku reconstructs your bridge  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                         BUILD ANOTHER ‚Üí     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 2: Recipient (Bridge Reconstruction)

```
Step 1: View clues
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ RECONSTRUCTION                                 ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Reconstruct the bridge.                                    ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Someone built a bridge between two concepts.               ‚îÇ
‚îÇ  These clues connect them:                                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    [clue1]  ¬∑  [clue2]  ¬∑  [clue3]  ¬∑  [clue4]     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                      ¬∑  [clue5]                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  What two words were being connected?                       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ANCHOR                          TARGET                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ           ‚îÇ                  ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                        SUBMIT GUESS ‚Üí       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Step 2: Results
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ RESULTS                                        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Bridge: [anchor] ‚Üê‚Üí [target]                               ‚îÇ
‚îÇ  Your guess: [guess_anchor] ‚Üê‚Üí [guess_target]               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  RECONSTRUCTION ACCURACY                                    ‚îÇ
‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë  82%                                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Your anchor guess was [X]% similar to the true anchor.     ‚îÇ
‚îÇ  Your target guess was [Y]% similar to the true target.     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ                                          TRY ANOTHER ‚Üí      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Phase 3: Sender Results (after recipient completes)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INS-001.2 ¬∑ YOUR RESULTS                                   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Bridge: [anchor] ‚Üê‚Üí [target]                               ‚îÇ
‚îÇ  Clues: [clue1] ¬∑ [clue2] ¬∑ [clue3] ¬∑ [clue4] ¬∑ [clue5]     ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  DIVERGENCE                                    78   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  predictable                               creative ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  How far your clues arc from the direct path.       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  RECONSTRUCTION (Human)                        82   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  opaque                                  transparent‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  How accurately your recipient recovered your       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  anchor-target pair.                                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  BASELINES                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Haiku (LLM):        71                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  What a reasoning AI inferred from your clues.      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Statistical:        64                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  What embedding geometry predicts.                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                                                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Your human recipient outperformed both baselines.  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Scoring Calculations

### 1. Divergence Score

Measures how far the participant's clues arc from the direct path between anchor and target.

```python
def calculate_divergence(anchor: str, target: str, clues: list[str], model) -> float:
    """
    Calculate mean perpendicular distance of clues from anchor-target line.
    
    Args:
        anchor: The anchor word
        target: The target word
        clues: List of 5 clue words
        model: Word embedding model (e.g., word2vec, GloVe)
    
    Returns:
        Divergence score (0-100 scale)
    """
    # Get embeddings
    anchor_vec = model.get_vector(anchor)
    target_vec = model.get_vector(target)
    
    # Define the line direction
    line_direction = target_vec - anchor_vec
    line_length_sq = np.dot(line_direction, line_direction)
    
    perpendicular_distances = []
    
    for clue in clues:
        clue_vec = model.get_vector(clue)
        
        # Vector from anchor to clue
        anchor_to_clue = clue_vec - anchor_vec
        
        # Project clue onto the line
        # projection_scalar t: where on the line [0=anchor, 1=target]
        projection_scalar = np.dot(anchor_to_clue, line_direction) / line_length_sq
        
        # Point on line closest to clue
        projection_point = anchor_vec + projection_scalar * line_direction
        
        # Perpendicular distance
        perp_distance = np.linalg.norm(clue_vec - projection_point)
        perpendicular_distances.append(perp_distance)
    
    # Mean perpendicular distance
    mean_perp_distance = np.mean(perpendicular_distances)
    
    # Normalize to 0-100 scale
    # Note: calibration needed based on embedding space characteristics
    # Typical cosine distances in word2vec range 0-2, perpendicular similar
    normalized_score = min(100, (mean_perp_distance / CALIBRATION_MAX) * 100)
    
    return normalized_score
```

**Interpretation:**
- Low divergence (0-30): Clues lie close to the direct path; predictable associations
- Medium divergence (30-70): Clues arc moderately from the path
- High divergence (70-100): Clues take a creative/circuitous route

### 2. Reconstruction Score

Measures how accurately the recipient recovered the anchor-target pair.

```python
def calculate_reconstruction(
    true_anchor: str, 
    true_target: str, 
    guessed_anchor: str, 
    guessed_target: str, 
    model
) -> dict:
    """
    Calculate reconstruction accuracy.
    
    Handles order ambiguity: recipient might swap anchor and target.
    
    Returns:
        Dictionary with overall score and component scores
    """
    # Get embeddings
    true_a = model.get_vector(true_anchor)
    true_t = model.get_vector(true_target)
    guess_a = model.get_vector(guessed_anchor)
    guess_t = model.get_vector(guessed_target)
    
    # Calculate similarities for both orderings
    # Ordering 1: guess_a ‚Üí true_a, guess_t ‚Üí true_t
    sim_a1 = cosine_similarity(guess_a, true_a)
    sim_t1 = cosine_similarity(guess_t, true_t)
    score_ordering1 = (sim_a1 + sim_t1) / 2
    
    # Ordering 2: guess_a ‚Üí true_t, guess_t ‚Üí true_a (swapped)
    sim_a2 = cosine_similarity(guess_a, true_t)
    sim_t2 = cosine_similarity(guess_t, true_a)
    score_ordering2 = (sim_a2 + sim_t2) / 2
    
    # Take better ordering
    if score_ordering1 >= score_ordering2:
        best_score = score_ordering1
        anchor_sim = sim_a1
        target_sim = sim_t1
        order_swapped = False
    else:
        best_score = score_ordering2
        anchor_sim = sim_a2
        target_sim = sim_t2
        order_swapped = True
    
    # Convert cosine similarity (typically 0-1) to percentage
    # Note: cosine sim can be negative; clamp to 0
    overall_pct = max(0, best_score) * 100
    anchor_pct = max(0, anchor_sim) * 100
    target_pct = max(0, target_sim) * 100
    
    return {
        "overall": overall_pct,
        "anchor_similarity": anchor_pct,
        "target_similarity": target_pct,
        "order_swapped": order_swapped,
        "exact_anchor_match": guessed_anchor.lower() == true_anchor.lower() or 
                             (order_swapped and guessed_anchor.lower() == true_target.lower()),
        "exact_target_match": guessed_target.lower() == true_target.lower() or
                             (order_swapped and guessed_target.lower() == true_anchor.lower())
    }
```

**Interpretation:**
- Low reconstruction (0-40): Recipient couldn't recover the bridge
- Medium reconstruction (40-70): Partial recovery
- High reconstruction (70-100): Successful communication

### 3. Statistical Baseline (Embedding-Based)

Provides a corpus-average baseline using embedding geometry. This is *not* the same as the Haiku reconstruction ‚Äî it's a deterministic calculation of what anchor-target pair best fits the clue vectors.

```python
def calculate_statistical_baseline(
    clues: list[str],
    true_anchor: str,
    true_target: str,
    model,
    vocabulary: list[str],
    top_k: int = 100
) -> dict:
    """
    Estimate what anchor-target pair a statistical model would infer from clues.
    
    Approach: Find vocabulary words that minimize total distance to all clues,
    then select the pair that best explains the clue pattern.
    """
    # Get clue embeddings
    clue_vecs = [model.get_vector(c) for c in clues]
    clue_centroid = np.mean(clue_vecs, axis=0)
    
    # Find candidate words close to clue centroid
    candidates = []
    for word in vocabulary:
        word_vec = model.get_vector(word)
        dist_to_centroid = np.linalg.norm(word_vec - clue_centroid)
        candidates.append((word, dist_to_centroid, word_vec))
    
    candidates.sort(key=lambda x: x[1])
    top_candidates = candidates[:top_k]
    
    # Score pairs: which pair of candidates best explains the clues?
    # Clues should lie "between" the anchor-target pair
    best_pair = None
    best_pair_score = -1
    
    for i, (word_a, _, vec_a) in enumerate(top_candidates):
        for j, (word_t, _, vec_t) in enumerate(top_candidates):
            if i >= j:
                continue
            
            # Score: how well do clues lie along this pair's axis?
            line_dir = vec_t - vec_a
            line_len_sq = np.dot(line_dir, line_dir)
            
            if line_len_sq < 1e-10:
                continue
            
            # Mean projection of clues onto line (should be ~0.5 for good bridge)
            # Plus: clues should have low perpendicular distance
            total_proj = 0
            total_perp = 0
            for clue_vec in clue_vecs:
                proj_scalar = np.dot(clue_vec - vec_a, line_dir) / line_len_sq
                proj_point = vec_a + proj_scalar * line_dir
                perp_dist = np.linalg.norm(clue_vec - proj_point)
                total_proj += proj_scalar
                total_perp += perp_dist
            
            mean_proj = total_proj / len(clues)
            mean_perp = total_perp / len(clues)
            
            # Good pair: mean projection near 0.5, low perpendicular distance
            proj_score = 1 - abs(mean_proj - 0.5) * 2  # 1 if centered, 0 if at ends
            perp_score = 1 / (1 + mean_perp)  # Higher is better
            
            pair_score = proj_score * perp_score
            
            if pair_score > best_pair_score:
                best_pair_score = pair_score
                best_pair = (word_a, word_t)
    
    if best_pair:
        # Calculate reconstruction score for the statistical guess
        recon = calculate_reconstruction(
            true_anchor, true_target,
            best_pair[0], best_pair[1],
            model
        )
        return {
            "guessed_anchor": best_pair[0],
            "guessed_target": best_pair[1],
            "reconstruction_score": recon["overall"],
            "method": "centroid_line_fit"
        }
    
    return {"reconstruction_score": 0, "method": "failed"}


### 4. Haiku Reconstruction (LLM-Based)

Claude Haiku acts as a generative recipient, reasoning about the clues to guess the anchor-target pair. This is qualitatively different from the embedding baseline ‚Äî Haiku may use pragmatic inference, world knowledge, and creative interpretation.

```python
import anthropic

client = anthropic.Anthropic()

def haiku_reconstruct(clues: list[str]) -> dict:
    """
    Have Claude Haiku guess the anchor-target pair from clues.
    
    Returns guessed words which are then scored using embeddings.
    """
    prompt = f"""You are playing a word game. Someone chose two words (an anchor and a target) and provided clues to help you guess them.

The clues are: {', '.join(clues)}

These five words are meant to connect or bridge between two concepts. What two words do you think were being connected?

Respond with exactly two words, separated by a comma. The first word is your guess for the anchor, the second for the target. Do not explain your reasoning."""

    response = client.messages.create(
        model="claude-3-5-haiku-20241022",
        max_tokens=50,
        messages=[{"role": "user", "content": prompt}]
    )
    
    # Parse response
    text = response.content[0].text.strip()
    parts = [p.strip().lower() for p in text.split(',')]
    
    if len(parts) >= 2:
        return {
            "guessed_anchor": parts[0],
            "guessed_target": parts[1],
            "raw_response": text
        }
    
    return {"error": "Could not parse response", "raw_response": text}
```

**Scoring Haiku's guess:** Use the same `calculate_reconstruction()` function with embedding-based cosine similarity. This allows direct comparison: did Haiku or the human recipient reconstruct more accurately?
```

---

## Data Model

### Games Table

```sql
CREATE TABLE games_bridging (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Sender info
    sender_id UUID REFERENCES users(id),
    sender_session_id TEXT,  -- For anonymous play
    
    -- Bridge definition
    anchor_word TEXT NOT NULL,
    target_word TEXT NOT NULL,
    clues TEXT[] NOT NULL,  -- Array of 1-5 clues
    
    -- Computed scores (calculated on submission via embeddings)
    divergence_score NUMERIC(5,2),
    
    -- Recipient info (populated when someone guesses)
    recipient_id UUID REFERENCES users(id),
    recipient_session_id TEXT,
    recipient_type TEXT CHECK (recipient_type IN ('human', 'haiku', 'stranger')),
    
    -- Recipient guesses (human or Haiku)
    guessed_anchor TEXT,
    guessed_target TEXT,
    
    -- Reconstruction scores (calculated via embeddings after guess)
    reconstruction_score NUMERIC(5,2),
    anchor_similarity NUMERIC(5,2),
    target_similarity NUMERIC(5,2),
    order_swapped BOOLEAN,
    exact_anchor_match BOOLEAN,
    exact_target_match BOOLEAN,
    
    -- Haiku reconstruction (LLM-based, generative)
    haiku_guessed_anchor TEXT,
    haiku_guessed_target TEXT,
    haiku_reconstruction_score NUMERIC(5,2),
    
    -- Statistical baseline (embedding-based, deterministic)
    statistical_guessed_anchor TEXT,
    statistical_guessed_target TEXT,
    statistical_baseline_score NUMERIC(5,2),
    
    -- Game state
    status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'completed', 'expired')),
    share_code TEXT UNIQUE,  -- For sharing links
    completed_at TIMESTAMP WITH TIME ZONE
);

-- Index for share links
CREATE INDEX idx_games_bridging_share_code ON games_bridging(share_code);

-- Index for user lookups
CREATE INDEX idx_games_bridging_sender ON games_bridging(sender_id);
CREATE INDEX idx_games_bridging_recipient ON games_bridging(recipient_id);
```

### Session Aggregates View

```sql
CREATE VIEW user_bridging_profile AS
SELECT 
    sender_id,
    COUNT(*) as games_played,
    AVG(divergence_score) as mean_divergence,
    STDDEV(divergence_score) as divergence_sd,
    -- Human reconstruction
    AVG(reconstruction_score) FILTER (WHERE recipient_type = 'human') as mean_human_reconstruction,
    -- Haiku (LLM) reconstruction
    AVG(haiku_reconstruction_score) as mean_haiku_reconstruction,
    -- Statistical (embedding) baseline
    AVG(statistical_baseline_score) as mean_statistical_baseline,
    -- Ratio: human vs Haiku (does your recipient outperform the LLM?)
    AVG(reconstruction_score) FILTER (WHERE recipient_type = 'human') / 
        NULLIF(AVG(haiku_reconstruction_score), 0) as human_vs_haiku_ratio,
    -- Ratio: human vs statistical (does your recipient outperform embedding geometry?)
    AVG(reconstruction_score) FILTER (WHERE recipient_type = 'human') / 
        NULLIF(AVG(statistical_baseline_score), 0) as human_vs_statistical_ratio
FROM games_bridging
WHERE status = 'completed'
GROUP BY sender_id;
```

---

## Implementation Notes

### Embedding Model vs. LLM

**Critical distinction:** This instrument uses two different AI systems for different purposes:

1. **Embedding Model (OpenAI text-embedding-3-small)**
   - Deterministic vector representations
   - Used for: divergence calculation, reconstruction accuracy scoring, statistical baseline
   - Represents corpus statistics ‚Äî given the math, there *is* a right answer
   - API: `openai.embeddings.create(model="text-embedding-3-small", input=word)`

2. **LLM (Claude Haiku)**
   - Generative model that reasons about clues
   - Used for: AI reconstruction (guessing the anchor-target pair)
   - No guaranteed right answer ‚Äî it infers, reasons, may be creative or wrong
   - Provides a different baseline: "how would a reasoning agent interpret these clues?"

**Why both matter:**
- Embedding baseline: "What pair does the geometry of these clues point to?"
- Haiku reconstruction: "What would a capable language-using agent infer?"
- Gap between them: If Haiku outperforms embedding baseline, clues contain pragmatic signal beyond vector geometry. If embedding baseline outperforms Haiku, clues are geometrically obvious but Haiku overthought it.

### Embedding Model Setup

```python
from openai import OpenAI

client = OpenAI()

def get_embedding(word: str) -> list[float]:
    """Get embedding vector for a word."""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=word.lower()
    )
    return response.data[0].embedding

def get_embeddings_batch(words: list[str]) -> dict[str, list[float]]:
    """Get embeddings for multiple words in one API call."""
    response = client.embeddings.create(
        model="text-embedding-3-small",
        input=[w.lower() for w in words]
    )
    return {
        words[i]: response.data[i].embedding 
        for i in range(len(words))
    }
```

### Handling Unusual Words

OpenAI's text-embedding-3-small generates embeddings for any text input. However, embeddings for highly unusual words, neologisms, or typos may have less stable representations. For the prototype, accept all inputs ‚Äî unusual words can be logged for later analysis of scoring reliability.

### Suggestion Feature

The "Suggest" buttons offer distant words to help users who need inspiration. This requires a curated vocabulary list to search against.

```python
import random

# Pre-computed: vocabulary list with cached embeddings
# Could be top 10k English nouns, or a curated interesting-word list
VOCABULARY: list[str] = [...]  # Load from file
VOCAB_EMBEDDINGS: dict[str, list[float]] = {
    word: get_embedding(word) for word in VOCABULARY
}

def suggest_distant_word(from_word: str = None) -> str:
    """
    Suggest a word distant from the input word.
    If no input, return a random word from vocabulary.
    """
    if from_word is None:
        return random.choice(VOCABULARY)
    
    from_embedding = get_embedding(from_word)
    
    # Find words with lowest cosine similarity
    similarities = []
    for word, emb in VOCAB_EMBEDDINGS.items():
        sim = cosine_similarity(from_embedding, emb)
        similarities.append((word, sim))
    
    # Sort by similarity (ascending) and pick from bottom 10%
    similarities.sort(key=lambda x: x[1])
    distant_candidates = similarities[:len(similarities) // 10]
    
    # Return random choice from distant candidates
    return random.choice(distant_candidates)[0]
```

**Behavior:**
- If anchor is empty and user clicks "Suggest": return random word
- If anchor has a value and user clicks "Suggest" for target: return word distant from anchor
- If target has a value and user clicks "Suggest" for anchor: return word distant from target

### Calibration Constants

The divergence score needs calibration based on empirical data. Initial approach:

1. Generate 1000 random anchor-target pairs
2. For each, sample "obvious" bridge words (high similarity to both)
3. Compute perpendicular distances
4. Use 95th percentile as CALIBRATION_MAX

```python
CALIBRATION_MAX = 0.8  # Placeholder; calibrate empirically
```

### API Endpoints

```
POST /api/games/bridging
  Body: { anchor, target, clues[] }  -- clues: 1-5 words
  Returns: { game_id, share_code, divergence_score }

GET /api/games/bridging/suggest
  Query: ?from=word (optional, suggests word distant from this)
  Returns: { suggestion }
  Note: Returns a word with low cosine similarity to the input,
        or a random word if no input provided

GET /api/games/bridging/:share_code
  Returns: { clues[], status }

POST /api/games/bridging/:share_code/guess
  Body: { guessed_anchor, guessed_target }
  Returns: { reconstruction_score, anchor_similarity, target_similarity }

GET /api/games/bridging/:game_id/results
  Returns: { full game data including all scores }

POST /api/games/bridging/:game_id/haiku-guess
  Triggers Claude Haiku reconstruction (generative)
  Returns: { guessed_anchor, guessed_target, reconstruction_score }

GET /api/games/bridging/:game_id/statistical-baseline
  Calculates embedding-based reconstruction (deterministic)
  Returns: { guessed_anchor, guessed_target, reconstruction_score }
```

---

## UI/UX Notes

### Visual Design

Follow existing INS-001 dark theme with gold accents. Key elements:

- **Anchor-target display:** Show as a horizontal span with endpoints
  ```
  coffee ‚Üê‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Üí sunshine
  ```

- **Clue input:** Vertical list, same as INS-001

- **Score displays:** Horizontal bars with labeled endpoints
  ```
  DIVERGENCE                                    78
  ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
  predictable                               creative
  ```

### Validation

- Anchor and target must be different words
- At least 1 clue required, maximum 5
- Clues must be single words
- Clues cannot be the anchor or target word
- Clues cannot be repeated

Note: No vocabulary validation needed ‚Äî OpenAI embeddings generate vectors for any text input.

### Responsive Behavior

- On mobile, stack anchor/target inputs vertically
- Clue inputs remain vertical list
- Score bars remain horizontal (may need smaller labels)

---

## Future Extensions (Out of Scope for Prototype)

1. **Challenge Mode:** Show semantic neighborhood (blocker) after baseline established
2. **Perspective Paths:** Oblique strategy prompts to redirect attention
3. **Network Comparisons:** Track share graph, compute network vs. stranger reconstruction
4. **Semantic Portability:** Ratio of stranger to network reconstruction
5. **Longitudinal Tracking:** Profile stability over time
6. **Alternative LLMs:** Compare reconstruction across different models (Haiku vs. Sonnet vs. GPT-4)
7. **Validation Studies:** Correlation with DAT, AUT, RAT per original proposal

---

## Revision History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-13 | Initial specification |
